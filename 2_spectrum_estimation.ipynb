{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf0eba4c-f151-4e54-8c4f-75185925acca",
   "metadata": {},
   "source": [
    "# 2. Spectrum Estimation, Crab Nebula\n",
    "\n",
    "We will be picking up from where we left in the previous tutorial.   \n",
    "In this one, we will be estimating the spectrum (i.e. the flux as a function of the energy) of the Crab Nebula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1530e4de-ca2c-4241-b5a1-10a7ff6bc15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - basic imports (numpy, astropy, regions, matplotlib)\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from regions import PointSkyRegion, CircleSkyRegion\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# - Gammapy's imports\n",
    "from gammapy.maps import Map, MapAxis, WcsGeom, RegionGeom\n",
    "from gammapy.data import DataStore, Observation\n",
    "from gammapy.datasets import SpectrumDataset, Datasets\n",
    "from gammapy.makers import (\n",
    "    SpectrumDatasetMaker,\n",
    "    WobbleRegionsFinder,\n",
    "    ReflectedRegionsBackgroundMaker,\n",
    ")\n",
    "from gammapy.modeling.models import (\n",
    "    PowerLawSpectralModel,\n",
    "    LogParabolaSpectralModel,\n",
    "    SkyModel,\n",
    "    create_crab_spectral_model,\n",
    ")\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.estimators import FluxPointsEstimator\n",
    "from gammapy.stats import WStatCountsStatistic\n",
    "\n",
    "# - setting up logging and ignoring warnings\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678e170d-b3bd-416c-92e0-e021022e7ec8",
   "metadata": {},
   "source": [
    "## 2.1. Spectrum Extraction\n",
    "\n",
    "Let us start from the previous homework, but let us do it with `Gammapy`!    \n",
    "We aim at building histograms of the events in the _on_ and _off_ regions as a function of the energy. By estimating the _spectrum_, we mean we would like to find a description, through an analytical function, of this distribution in energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9cf3c1-0b5f-466c-962a-56de90027c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us load the observations again\n",
    "datastore = DataStore.from_dir(\"../acme_magic_odas_data/data/CrabNebula\")\n",
    "observations = datastore.get_observations(required_irf=[\"rad_max\", \"aeff\", \"edisp\"])\n",
    "print(len(observations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd928456-f1e8-48e5-a7cc-5751419c59d5",
   "metadata": {},
   "source": [
    "### 2.1.1. The `RAD_MAX` table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726ef8c-1d99-4865-9f40-f72e3fc054c0",
   "metadata": {},
   "source": [
    "In general, with increasing energy, the spatial resolution of the telescope will improve. This means that we might use tighter $\\theta^2$ cuts (i.e. smaller _on_ and _off_ regions), the idea being that the $\\theta^2$ histogram will become much more peaked as the energy increases (could you observe this in Exercise 1.2?). \n",
    "\n",
    "Pre-optimised $\\theta^2$ cuts are available in the `rad_max` attribute of each observation. They correspond to the `RAD_MAX` data unit in the `.fits` file. We plot the optimised $\\theta^2$ cut in each bin, and, for comparison, the $\\theta^2$ cut we used in the previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807f405-4445-4a09-bd1b-35c6211a8d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "rad_max = observations[0].rad_max\n",
    "rad_max.plot_rad_max_vs_energy(\n",
    "    ax=ax,\n",
    "    ls=\"--\",\n",
    "    marker=\".\",\n",
    "    label=\"optimised \" + r\"$\\theta^2$\" + \" cut\",\n",
    "    drawstyle=\"steps-mid\",\n",
    ")\n",
    "ax.axhline(0.2, ls=\"--\", lw=1, label=\"fixed cut (previous tutorial)\", color=\"crimson\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11021990-c4f5-4bdc-a6a7-79442830b897",
   "metadata": {},
   "source": [
    "### 2.1.2. From `Observations` to `Datasets`\n",
    "\n",
    "We will now delegate all the steps of spectrum extraction to `Gammapy` (we will basically let `Gammapy` do the homework we had in the previous tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de05cb-8855-4002-b034-64765cff937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us define the parameters of the spectrum extraction\n",
    "# - we need to specify only the center of the on region,\n",
    "# its radius will be fetched from the RAD_MAX table.\n",
    "crab_coords = SkyCoord.from_name(\"Crab Nebula\")\n",
    "on_region = PointSkyRegion(crab_coords)\n",
    "\n",
    "# - let us define the energy axes over which we want:\n",
    "# -- to bin the counts (estimated energies) and\n",
    "energy_axis = MapAxis.from_energy_bounds(\n",
    "    10, 1e5, nbin=20, per_decade=False, unit=\"GeV\", name=\"energy\"\n",
    ")\n",
    "# -- to interpolate the IRFs (true energies)\n",
    "energy_axis_true = MapAxis.from_energy_bounds(\n",
    "    10, 1e5, nbin=28, per_decade=False, unit=\"GeV\", name=\"energy_true\"\n",
    ")\n",
    "\n",
    "# let us create an empty dataset with this spatial and energy structure / binning\n",
    "geom = RegionGeom.create(region=on_region, axes=[energy_axis])\n",
    "dataset_empty = SpectrumDataset.create(geom=geom, energy_axis_true=energy_axis_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5639ed28-dd3b-46a5-81ad-dcdcc9a45c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_maker = SpectrumDatasetMaker(\n",
    "    containment_correction=False, selection=[\"counts\", \"exposure\", \"edisp\"]\n",
    ")\n",
    "# use 3 off regions to estimate the background\n",
    "region_finder = WobbleRegionsFinder(n_off_regions=3)\n",
    "bkg_maker = ReflectedRegionsBackgroundMaker(region_finder=region_finder)\n",
    "\n",
    "datasets = Datasets()\n",
    "\n",
    "for observation in observations:\n",
    "    dataset = dataset_maker.run(\n",
    "        dataset_empty.copy(name=str(observation.obs_id)), observation\n",
    "    )\n",
    "    dataset_on_off = bkg_maker.run(dataset, observation)\n",
    "    datasets.append(dataset_on_off)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42fbd8-63cf-4480-b16f-5dbe7131bb46",
   "metadata": {},
   "source": [
    "We turned our observations in `DataSets`. What do they contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46714d30-aae7-48ba-b663-bd3930c78e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[1].peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ba3a79-9276-4e55-b84e-2cdeeddb8552",
   "metadata": {},
   "source": [
    "## 2.2 Spectrum Fit\n",
    "\n",
    "We see the array of _on_ and _off_ counts, and the two IRF we previously examined.    \n",
    "How should we use them, and what does it mean to estimate a spectrum?\n",
    "\n",
    "\n",
    "To obtain a measurement of the specturm, it is commonly assumed that a simple analytical function describes the gamma-ray (differential) flux $\\Phi$ vs energy. The most common example is a power-law\n",
    "\n",
    "$$\n",
    "    \\frac{{\\rm d}\\phi}{{\\rm d}E}(E; \\Phi_0, \\Gamma, E_0)\\,[{\\rm TeV}^{-1}\\,{\\rm cm}^{-2}\\,{\\rm s}^{-1}] = \n",
    "    \\Phi_0 \\left(\\frac{E}{E_0}\\right)^{-\\Gamma}\n",
    "    \\tag{2.1}\n",
    "$$\n",
    "\n",
    "where $\\Phi_0$ is the flux normalization at the reference energy $E_0$, $\\Gamma$ is the spectral index (slope of the power law), and $E_0$ is the reference energy (commonly chosen near the middle of the fitted energy range).  \n",
    "\n",
    "Another commonly used spectral model is the log-parabola, which allows for curvature in the spectrum:  \n",
    "\n",
    "$$\n",
    "\\frac{{\\rm d}\\phi}{{\\rm d}E}(E; \\Phi_0, \\Gamma, \\beta, E_0) =\n",
    "\\Phi_0 \\left(\\frac{E}{E_0}\\right)^{-\\Gamma - \\beta \\, \\log\\!\\left(\\frac{E}{E_0}\\right)}\n",
    "\\tag{2.2}\n",
    "$$\n",
    "\n",
    "where $\\beta$ is the curvature parameter (with $\\beta = 0$ the model reduces to a pure power law).\n",
    "\n",
    "Let us look at measurements of the spectrum of the Crab from publications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359bcd8e-0dac-45d8-850d-0b7fd97b5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image\n",
    "img = mpimg.imread(\"img/crab_sed_magic.png\")\n",
    "# display image\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.imshow(img)\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533aa788-19f5-4d71-a093-dd7a455748c0",
   "metadata": {},
   "source": [
    "Reference: [MAGIC Collaboration (2015), JHEAP, 5, p. 30-38.](https://ui.adsabs.harvard.edu/abs/2015JHEAp...5...30A/abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a7d95-226d-441a-9d53-609c0814e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image\n",
    "img = mpimg.imread(\"img/crab_sed_hess.png\")\n",
    "# display image\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.imshow(img)\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c11f94-5549-4178-8652-9e1db3f34f2b",
   "metadata": {},
   "source": [
    "Reference: [H.E.S.S. Collaboration (2006), A&A, 457, 3, pp.899-915](https://ui.adsabs.harvard.edu/abs/2006A%26A...457..899A/abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba7244-2440-4551-832b-a65ccbc4ba80",
   "metadata": {},
   "source": [
    "Let us now plot some of the examples of analytical spectra available in `Gammapy`.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f9cc9-bbb4-4a76-9e47-0007d50965af",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_bounds = [80 * u.GeV, 10 * u.TeV]\n",
    "pwl = PowerLawSpectralModel()\n",
    "pwl.plot(energy_bounds, label=\"power law\")\n",
    "lp = LogParabolaSpectralModel(\n",
    "    amplitude=7e-11 * u.Unit(\"TeV-1 cm-2 s-1\"), reference=100 * u.GeV\n",
    ")\n",
    "lp.plot(energy_bounds, label=\"log parabola\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765e1b6-b7cf-4746-857e-6a758d72c3f6",
   "metadata": {},
   "source": [
    "We would like to find the flux vs energy (the parameters, given an assumed specrum) that would produce in our detector the same counts we observed. The issue is that flux is an absolute physical quantity, whereas the data (observed counts) are not absolute as they depend on our detector.\n",
    "\n",
    "How can we adjust the parameters $\\hat{\\theta}$ of the analytical spectrum to the counts that we have extracted? That's where the IRF come into place. The IRF allow us to go from gamma-ray flux to instrument counts and vice versa. By folding (i.e. convolving) the analytical flux model with the response of the system we can obtain counts vs energy. \n",
    "\n",
    "The number of model (or _predicted_) counts in a given energy bin $\\Delta E'$ is:\n",
    "\n",
    "$$\n",
    "g_{i}(\\hat{\\theta}) = \n",
    "    t_{\\rm eff} \\int_{\\Delta E'} {\\rm d}E' \\int_{0}^{\\infty} {\\rm d}E \\;\n",
    "    A_{\\rm eff}(E) M(E'|E) \\frac{{\\rm d}\\phi}{{\\rm d}E}(E; \\hat{\\theta}),\n",
    "\\tag{2.2}\n",
    "$$\n",
    "\n",
    "where $A_{\\rm eff}(E)$ represents the effective area and $M(E'|E)$ the energy dispersion.\n",
    "\n",
    "How can we decide which (predicted) counts best describe our model? We do this by using a likelihood, specifically the one we already introduced in the previous notebook, in Eq. 1.3. We have to take into account that we have counts as a function of the energy, therefore, we have to produce a likelihood term for each of the estimated energy bins. The total likelihood for our dataset, accounting for the observed and estimated counts in each energy bin, reads:\n",
    "\n",
    "$$ \n",
    "\\mathcal{L}(\\hat{\\theta}) = \n",
    "    \\displaystyle \\Pi_{i=1}^{N} {\\rm P}(g_i(\\hat{\\theta}) + \\alpha b_i; N_{{\\rm on}, i}) {\\rm P}(b_i; N_{{\\rm off}, i})\n",
    "\\tag{2.3}\n",
    "$$\n",
    "\n",
    "where $i$ is an index that runs over $N$ estimated energy bins, and with the notation $g_i(\\hat{\\theta})$ denoting that the number of expected signal counts depend on the model parameters. $b_i$, the number of background counts, is typically treated as a nuisance parameter. The likelihood is maximised by varying the spectral parameters $\\hat{\\theta}$, and hence the number of predicted counts. `Gammapy` will take care of all these computations for us.\n",
    "\n",
    "It is customary to fit the spectrum in an energy range that is determined by the observing conditions (especially the zenith angle that impacts the energy threshold of the instrument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08273e94-e616-44df-9dc4-8f286543981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the energy range to be used for the fitting\n",
    "e_min = 0.08 * u.TeV\n",
    "e_max = 20 * u.TeV\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset.mask_fit = dataset.counts.geom.energy_mask(e_min, e_max)\n",
    "\n",
    "# now define the model to be fitted\n",
    "spectral_model = LogParabolaSpectralModel(\n",
    "    amplitude=5e-12 * u.Unit(\"TeV-1 cm-2 s-1\"),\n",
    "    reference=1 * u.TeV,\n",
    "    alpha=2.3 * u.Unit(\"\"),\n",
    "    beta=0.1 * u.Unit(\"\"),\n",
    ")\n",
    "# trick to facilitate ULs computation\n",
    "spectral_model.amplitude.min = 1e-20\n",
    "spectral_model.amplitude.max = 1e-5\n",
    "print(spectral_model)\n",
    "\n",
    "# we have to assign the spectral model to a model of the sky\n",
    "# that in this case will consist of a single source\n",
    "model = SkyModel(spectral_model=spectral_model, name=\"CrabNebula\")\n",
    "\n",
    "datasets.models = [model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f512df77-8db9-4ee9-922f-d922d3b9db04",
   "metadata": {},
   "source": [
    "We can see the parameters, and now that we have assigned the model, we can see something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95e78a-b5f5-4899-87e3-ffd55ce0942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0].plot_excess()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2f68e7-de94-4db7-bb6e-5580caefc041",
   "metadata": {},
   "source": [
    "We can also check the contribution of this data set to the total likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bb572e-9fc3-4324-8b80-3818a411a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0].stat_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ea96ef-16fa-4a2b-8b50-227129f9a8c5",
   "metadata": {},
   "source": [
    "As we can see, the counts predicted by the model we specified for the data set are one order of magnitude below the observed source counts. \n",
    "\n",
    "To get a feeling of how the likelihood minimisation for the fit works, let us go back to the definition of the spectral analytical function and change the amplitude parameter to `5e-11 * u.Unit(\"TeV-1 cm-2 s-1\")`. What happens to the predicted counts? And what happens to the likelihood statistics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59658335-5b26-4914-9b75-c88f7dee7a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_model.amplitude.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959151a-c3b4-48e5-85b4-0c8b79a47052",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_model.amplitude.value = 5e-11\n",
    "\n",
    "datasets[0].plot_excess()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dc665d-c846-4806-ba63-b9b83d7b169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0].stat_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313c7d29-01b0-4d37-94a9-ee0ad45e1778",
   "metadata": {},
   "source": [
    "You have now an intuition of how the fitting routine works. The parameters will be changed until the best agreement between observed and predicted counts is found. This agreement is statistically quantified by the likelihood, which is what is actually maximised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9152b2-2396-478c-a6db-d66bdc190693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the fit!\n",
    "fit = Fit()\n",
    "results = fit.run(datasets=datasets)\n",
    "print(results)\n",
    "print(spectral_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a6c5b-40af-4d8c-8967-ac5262ffab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_spectrum, ax_residuals = datasets[0].plot_fit()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eaef7e-4ef3-49d5-8a15-5835ab6ed0c1",
   "metadata": {},
   "source": [
    "We can now plot the spectrum obtained by our fitting procedure. It is common in high-energy astrophysics, to represent instead of the differential flux the Spectral Energy Distribution (SED) obtained as $E^2\\frac{{\\rm d}\\phi}{{\\rm d}E} [{\\rm TeV}^{-1}\\,{\\rm cm}^{-2}\\,{\\rm s}^{-1}]$ that represent the how the emitted power is distributed over the electromagnetic spectrum. We compare the results we have obtained with a theoretical model of the SED and with another measurement performed by MAGIC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f49c148-9da3-4bc4-ad82-3292564ff030",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plot_kwargs = {\n",
    "    \"sed_type\": \"e2dnde\",\n",
    "    \"yunits\": u.Unit(\"TeV cm-2 s-1\"),\n",
    "    \"xunits\": u.GeV,\n",
    "}\n",
    "\n",
    "energy_range = [80 * u.GeV, 20 * u.TeV]\n",
    "\n",
    "spectral_model.plot(\n",
    "    energy_range,\n",
    "    ax=ax,\n",
    "    color=\"crimson\",\n",
    "    ls=\"-\",\n",
    "    label=\"LST\",\n",
    "    **plot_kwargs,\n",
    ")\n",
    "spectral_model.plot_error(\n",
    "    energy_range, ax=ax, facecolor=\"crimson\", alpha=0.4, **plot_kwargs\n",
    ")\n",
    "\n",
    "crab_meyer = create_crab_spectral_model(\"meyer\")\n",
    "crab_meyer.plot(\n",
    "    energy_range,\n",
    "    ax=ax,\n",
    "    label=\"Meyer et al. (2010)\",\n",
    "    color=\"k\",\n",
    "    ls=\"--\",\n",
    "    **plot_kwargs,\n",
    ")\n",
    "\n",
    "crab_magic = create_crab_spectral_model(\"magic_lp\")\n",
    "crab_magic.plot(\n",
    "    energy_range,\n",
    "    ax=ax,\n",
    "    label=\"MAGIC Collaboration (2015)\",\n",
    "    color=\"dodgerblue\",\n",
    "    ls=\"--\",\n",
    "    **plot_kwargs,\n",
    ")\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlabel(r\"$E\\,/\\,{\\rm GeV}$\")\n",
    "ax.set_ylabel(\n",
    "    r\"$E^2 {\\rm d}\\phi/{\\rm d}E\\,/\\,({\\rm TeV}\\,{\\rm cm}^{-2}\\,{\\rm s}^{-1})$\"\n",
    ")\n",
    "ax.set_ylim([8e-13, 2e-10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d419e70d-acb1-4dee-b0c0-56b7790319d4",
   "metadata": {},
   "source": [
    "## 2.4. Flux Points\n",
    "\n",
    "Finally we also compute spectral data points or _flux points_. They are basically a flux measurement over different energy bins. Broadly speaking, they have two objectives:\n",
    "1) when we fit the broad-band spectrum via the likelihood maximisation - as we have just shown - we are assuming that the entire spectrum is described by a single analytic smooth function. This type of analysis is therefore not sensitive to any sharp feature in the spectrum;\n",
    "2) we are adopting an analytical function to provide a broad-band flux measurements, yet, at a later stage, other astrophysicists might want to fit a physical model to our gamma-ray data. In order to do so they should have access to the data sets (counts + IRF) that we are using. In case this data are proprietary we can provide a simplified and easier way to handle flux measurements.\n",
    "\n",
    "To compute flux points, `Gammapy` starts from the best-fit spectrum obtained from the broad-band likelihood fit and re-adjusts it spearately to the events within each energy bin. Note theat only the amplitude ($\\phi_0$ in Eq. 2.1) of the spectrum is re-fitted. Basically, the spectrum we obtained from the broad-band likelihood fit is scaled up and down to adjust independently to the counts in each energy bin.\n",
    "\n",
    "Let us use the same binning we have used in estimated energies and select an interval compatible with what was used in the likelihood fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61216b47-7fd2-45d9-90b2-b3ab2e4fab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_edges = datasets[0].counts.geom.axes[\"energy\"].edges\n",
    "fpe_lst = FluxPointsEstimator(\n",
    "    energy_edges=energy_edges, source=\"CrabNebula\", selection_optional=\"all\"\n",
    ")\n",
    "flux_points = fpe_lst.run(datasets=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dfa951-8743-46ff-b1fe-be1fc916c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "flux_points.plot(\n",
    "    ax=ax,\n",
    "    sed_type=\"e2dnde\",\n",
    "    color=\"darkorange\",\n",
    "    label=\"flux points\",\n",
    ")\n",
    "flux_points.plot_ts_profiles(ax=ax, sed_type=\"e2dnde\")\n",
    "spectral_model.plot(\n",
    "    energy_range,\n",
    "    ax=ax,\n",
    "    color=\"crimson\",\n",
    "    ls=\"--\",\n",
    "    lw=2,\n",
    "    sed_type=\"e2dnde\",\n",
    "    label=\"broad-band likelihood fit\",\n",
    ")\n",
    "ax.set_xlim([80, 2e4])\n",
    "ax.set_xlabel(r\"$E\\,/\\,{\\rm GeV}$\")\n",
    "ax.set_ylabel(\n",
    "    r\"$E^2 {\\rm d}\\phi/{\\rm d}E\\,/\\,({\\rm TeV}\\,{\\rm cm}^{-2}\\,{\\rm s}^{-1})$\"\n",
    ")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd011f49-c210-4b24-b663-ab6b22a72058",
   "metadata": {},
   "source": [
    "## Exercise 2.1.\n",
    "\n",
    "When estimating the spectral parameters using all the observations, we have a likelihood term like in Eq. 2.3 for each of the runs.  \n",
    "When we _stack_ the observations, we create a single `SpectrumDataset` from all the observations together.   \n",
    "_on_ and _off_ counts are simply summed in each estimated energy bin, IRF components are averaged, weighted by the observation time.\n",
    "\n",
    "Stack all the Crab Nebula observations (check the `Gammapy` docs) and re-perform the fit using the single dataset thus obtained. Check the results against those of the fit using all the observations simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6140216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
