{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a06de0c",
   "metadata": {},
   "source": [
    "# 3. Estimation of the flux of a variable source, Mrk421\n",
    "\n",
    "In the first two introductory notebooks, we considered Crab Nebula for its property of being the brightest **steady** emitter in the gamma-ray sky. Let us examine now a source whose flux is not constant in time, Mrk421."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d149e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - basic imports (numpy, astropy, regions, matplotlib)\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.time import Time \n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io.fits.verify import VerifyWarning\n",
    "from regions import PointSkyRegion, CircleSkyRegion\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# - Gammapy's imports\n",
    "from gammapy.maps import Map, MapAxis, WcsGeom, RegionGeom\n",
    "from gammapy.data import DataStore, Observation\n",
    "from gammapy.datasets import SpectrumDataset, Datasets, FluxPointsDataset\n",
    "from gammapy.makers import (\n",
    "    SpectrumDatasetMaker,\n",
    "    WobbleRegionsFinder,\n",
    "    ReflectedRegionsBackgroundMaker,\n",
    ")\n",
    "from gammapy.modeling.models import (\n",
    "    PowerLawSpectralModel,\n",
    "    LogParabolaSpectralModel,\n",
    "    ConstantSpectralModel,\n",
    "    SkyModel,\n",
    "    LinearTemporalModel,\n",
    "    SineTemporalModel\n",
    ")\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.estimators import (\n",
    "    FluxPointsEstimator,\n",
    "    LightCurveEstimator\n",
    ")\n",
    "from gammapy.stats import WStatCountsStatistic\n",
    "\n",
    "# - setting up logging and ignoring warnings\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore', VerifyWarning)\n",
    "    # do stuff here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828c1d0",
   "metadata": {},
   "source": [
    "## 3.1. Data Reduction\n",
    "As before, let us load all the Mrk421 observations and reduce the data.   \n",
    "Let us focus on the days between the 10th and the 20th of April, where the most intense variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121cc320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load observations\n",
    "datastore = DataStore.from_dir(\"../acme_magic_odas_data/Mrk421\")\n",
    "observations = datastore.get_observations(required_irf=[\"rad_max\", \"aeff\", \"edisp\"])\n",
    "print(f\"total observations : {len(observations)}\")\n",
    "\n",
    "# select observations between 10th and 20th of April\n",
    "times = [\"2013-04-10T00:00:00\", \"2013-04-20T00:00:00\"]\n",
    "time_intervals = Time(times, format='isot', scale='utc')\n",
    "observations = observations.select_time(time_intervals)\n",
    "print(f\"selected observations : {len(observations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us define the parameters of the spectrum extraction\n",
    "# - we need to specify only the center of the on region,\n",
    "# its radius will be fetched from the RAD_MAX table.\n",
    "crab_coords = SkyCoord.from_name(\"Mrk421\")\n",
    "on_region = PointSkyRegion(crab_coords)\n",
    "\n",
    "# - let us define the energy axes over which we want:\n",
    "# -- to bin the counts (estimated energies) and\n",
    "energy_axis = MapAxis.from_energy_bounds(\n",
    "    10, 1e5, nbin=20, per_decade=False, unit=\"GeV\", name=\"energy\"\n",
    ")\n",
    "# -- to interpolate the IRFs (true energies)\n",
    "energy_axis_true = MapAxis.from_energy_bounds(\n",
    "    10, 1e5, nbin=28, per_decade=False, unit=\"GeV\", name=\"energy_true\"\n",
    ")\n",
    "\n",
    "# let us create an empty dataset with this spatial and energy structure / binning\n",
    "geom = RegionGeom.create(region=on_region, axes=[energy_axis])\n",
    "dataset_empty = SpectrumDataset.create(geom=geom, energy_axis_true=energy_axis_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d62951-d1b0-43e4-a444-23f8d5d77c35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_maker = SpectrumDatasetMaker(\n",
    "    containment_correction=False, selection=[\"counts\", \"exposure\", \"edisp\"]\n",
    ")\n",
    "# use 3 off regions to estimate the background\n",
    "region_finder = WobbleRegionsFinder(n_off_regions=3)\n",
    "bkg_maker = ReflectedRegionsBackgroundMaker(region_finder=region_finder)\n",
    "\n",
    "datasets = Datasets()\n",
    "\n",
    "for observation in observations:\n",
    "    dataset = dataset_maker.run(\n",
    "        dataset_empty.copy(name=str(observation.obs_id)), observation\n",
    "    )\n",
    "    dataset_on_off = bkg_maker.run(dataset, observation)\n",
    "    datasets.append(dataset_on_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee896b7d-6205-4137-8f81-0a323419ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0].peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2745d60-befe-4d60-84d2-4a8c43b50d18",
   "metadata": {},
   "source": [
    "We obtained the one-dimensional data sets as before.\n",
    "\n",
    "## 3.2. Light curve: flux vs time estimation\n",
    "\n",
    "We are now concerned with studying the flux as a function of time: how could we measure it?      \n",
    "One option would certainly be to perform the spectrum estimation with the method previously demostrated per each of the observations separately, to measure spectral changes day by day or even run by run. To measure variability, it is common practice in astronomy to compile a _light curve_, a graph of the light intensity as a function of time. To represent the brightness in gamma-ray of our source we will consider its integral flux above a certain threshold, $E_{\\rm thr}$, that can depend on the analysis, or on the physics we are interested in\n",
    "\n",
    "$$\n",
    "    \\phi(E > E_{\\rm thr})\\,[{\\rm cm}^{-2}\\,{\\rm s}^{-1}] = \n",
    "    \\int_{E_{\\rm thr}}^{\\infty} \\frac{{\\rm d}\\phi}{{\\rm d}E}(E; \\hat{\\theta})\\,{\\rm d}E\n",
    "$$\n",
    "\n",
    "where we $\\hat{\\theta}$ represent the parameters of the spectral model. How are these treated if we aim to estimate the integral flux? One could in principle perform the likelihood fit of the previous notebook to determine $\\frac{{\\rm d}\\phi}{{\\rm d}E}(E; \\hat{\\theta})$ for all the events in a given interval of time (might be an observation, a day, a week), and then simply integrate the spectrum obtained.\n",
    "\n",
    "It is more common practice to fix the parameters of the spectrum adopted, and then simply adjust the normalisation $\\phi_0$, exactly as we did when we computed flux points. In that case, we readjusted the best-fit $\\phi_0$ using all the events within an estimated energy bin. We will now re-adjust it to the events in a single time interval.\n",
    "Given the parallel between the processes of flux points and light curve estimation, `Gammapy` provides a `LightCurveEstimator`  that works very simlarly to the `FluxPointsEstimator`, i.e. repeating the likelihood fit in each of the time bin (instead of the energy ones).\n",
    "\n",
    "Let us then compute the light curve for Mrk421. Which model should we assume. In the paper presenting this dataset ([MAGIC Collaboration (2020)](https://ui.adsabs.harvard.edu/abs/2020ApJS..248...29A/abstract)) we read:\n",
    "\n",
    "\n",
    "> [...] the VHE gamma-ray spectrum from the full nine day data set [...] is well represented by the following log-parabola function:    \n",
    "> $$ \\frac{{\\rm d}\\phi}{{\\rm d}E} = \\phi_0 \\left( \\frac{E}{0.3\\,{\\rm TeV}} \\right)^{- 2.14 - 0.45 \\log_{10}(\\frac{E}{0.3\\,{\\rm TeV}})} $$\n",
    "\n",
    "The amplitude parameter is not specified. Let us see if we can recover the same value fitting all the data together, let us stack and fit them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c60787e-f663-496f-a1dc-9ec48633aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stacked = datasets.stack_reduce()\n",
    "\n",
    "# let us use the LP model, use the same reference energy of the paper\n",
    "spectral_model = LogParabolaSpectralModel(\n",
    "    amplitude=5e-12 * u.Unit(\"TeV-1 cm-2 s-1\"),\n",
    "    reference=0.3 * u.TeV,\n",
    "    alpha=2.3 * u.Unit(\"\"),\n",
    "    beta=0.1 * u.Unit(\"\"),\n",
    ")\n",
    "model = SkyModel(spectral_model=spectral_model, name=\"Mrk421\")\n",
    "\n",
    "# let us use a reasonable energy range for fitting\n",
    "e_min = 0.08 * u.TeV\n",
    "e_max = 10 * u.TeV\n",
    "dataset_stacked.counts.geom.energy_mask(e_min, e_max)\n",
    "\n",
    "# assign the model to the\n",
    "dataset_stacked.models = [model]\n",
    "\n",
    "# run the fit!\n",
    "fit = Fit()\n",
    "results = fit.run(datasets=dataset_stacked)\n",
    "print(results)\n",
    "print(spectral_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20853fff-266c-4e58-8037-654a06fbd2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"alpha = {spectral_model.alpha.value:.2f} +/- {spectral_model.alpha.error:.2f}\")\n",
    "# the log in Gammapy's log parabola is in base e\n",
    "# the one in the paper is in base 10, make the conversion\n",
    "beta = spectral_model.beta.value / np.log10(np.e)\n",
    "beta_err = spectral_model.beta.error / np.log10(np.e)\n",
    "print(f\"beta = {beta:.2f} +/- {beta_err:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff6a784-60c3-4b72-99d8-029b50685569",
   "metadata": {},
   "source": [
    "We, obtained values quite similar to the average spectrum presented in the paper, let us go ahead and compute the LC with the `LightCurveEstimator`, if no time interval is specified, then a flux point per each observation will be estimated. Let us compute the light curve above 1 TeV, as done in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac89ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy range in which the flux has to be integrated\n",
    "energy_edges = [1 * u.TeV, 100 * u.TeV]\n",
    "\n",
    "# rember to assing the model to the datasets\n",
    "datasets.models = [model]\n",
    "\n",
    "light_curve_estimator_run_wise = LightCurveEstimator(\n",
    "    energy_edges=energy_edges,\n",
    "    source=\"Mrk421\",\n",
    "    reoptimize=False,\n",
    "    n_sigma_ul=3,\n",
    ")\n",
    "\n",
    "light_curve_run_wise = light_curve_estimator_run_wise.run(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e57ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5)) \n",
    "light_curve_run_wise.plot(\n",
    "    ax=ax,\n",
    "    sed_type=\"flux\",\n",
    "    marker=\".\"\n",
    ")\n",
    "ax.set_yscale(\"linear\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd77518f-83d4-4478-bb80-b7edf771e3dc",
   "metadata": {},
   "source": [
    "Let us compute daily and weekly fluxes as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c0efa-e170-4bbd-befa-fba46a0c29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_time_intervals = [\n",
    "    Time([56391.5, 56392.5], format=\"mjd\", scale=\"utc\"),\n",
    "    Time([56392.5, 56393.5], format=\"mjd\", scale=\"utc\"),\n",
    "    Time([56393.5, 56394.5], format=\"mjd\", scale=\"utc\"),\n",
    "    Time([56394.5, 56395.5], format=\"mjd\", scale=\"utc\"),\n",
    "    Time([56395.5, 56396.5], format=\"mjd\", scale=\"utc\"),\n",
    "    Time([56396.5, 56397.5], format=\"mjd\", scale=\"utc\"),\n",
    "    Time([56397.5, 56398.5], format=\"mjd\", scale=\"utc\"),\n",
    "    Time([56398.5, 56399.5], format=\"mjd\", scale=\"utc\"),\n",
    "    Time([56399.5, 56400.5], format=\"mjd\", scale=\"utc\"),\n",
    "    Time([56400.5, 56401.5], format=\"mjd\", scale=\"utc\"),\n",
    "    Time([56401.5, 56402.5], format=\"mjd\", scale=\"utc\"),\n",
    "]\n",
    "\n",
    "light_curve_estimator_daily = LightCurveEstimator(\n",
    "    energy_edges=energy_edges,\n",
    "    time_intervals=daily_time_intervals,\n",
    "    source=\"Mrk421\",\n",
    "    reoptimize=False,\n",
    "    n_sigma_ul=3,\n",
    ")\n",
    "\n",
    "light_curve_estimator_day = LightCurveEstimator(\n",
    "    energy_edges=energy_edges,\n",
    "    time_intervals=[Time([56394.5, 56395.5], format=\"mjd\", scale=\"utc\")],\n",
    "    source=\"Mrk421\",\n",
    "    reoptimize=False,\n",
    "    n_sigma_ul=3,\n",
    ")\n",
    "\n",
    "light_curve_daily = light_curve_estimator_daily.run(datasets)\n",
    "light_curve_day = light_curve_estimator_day.run(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70329027-819f-423d-bb4f-f99de304e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "light_curve_run_wise.plot(\n",
    "    ax=ax,\n",
    "    sed_type=\"flux\",\n",
    "    marker=\".\",\n",
    "    label=\"run-wise binning\",\n",
    "    alpha=0.6,\n",
    ")\n",
    "light_curve_day.plot(\n",
    "    ax=ax,\n",
    "    sed_type=\"flux\",\n",
    "    marker=\",\",\n",
    "    label=\"one night\",\n",
    ")\n",
    "light_curve_daily.plot(\n",
    "    ax=ax,\n",
    "    sed_type=\"flux\",\n",
    "    marker=\",\",\n",
    "    label=\"nightly binning\",\n",
    "    elinewidth=2,\n",
    "    \n",
    ")\n",
    "ax.set_yscale(\"linear\")\n",
    "ax.set_ylim([0, 4e-10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a75bb-4a0a-4402-8649-dd91abe1fb60",
   "metadata": {},
   "source": [
    "The 13 of April definitely looks the day with the highest flux, and the one with most variability.         \n",
    "Therefore it might be interesting to check the flux on smaller time scales than the day or the 20 minutes of the run. \n",
    "We can define even smaller time intervals, for example 10 minutes, even smaller than the run duration.   \n",
    "\n",
    "We will use again the `select_time` function of the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f82f2-3f98-4a8c-bb81-3b86be3a83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first select only the 13 of April from the observations\n",
    "time_day_start = Time(\"2013-04-12T12:00\")\n",
    "time_day_end = Time(\"2013-04-13T12:00\")\n",
    "time_interval_day = Time([time_day_start, time_day_end])\n",
    "\n",
    "observations_day = observations.select_time(time_interval_day)\n",
    "print(f\"selected observations : {len(observations_day)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44917762-b034-4fab-8763-4f6edc57d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us now split this observation in even smaller chunks of 10 minutes\n",
    "duration = 10 * u.min\n",
    "\n",
    "# let us split the day in 10 minutes interval\n",
    "time_intervals_10min = [time_day_start]\n",
    "\n",
    "while time_intervals_10min[-1] <= time_day_end:\n",
    "    time_intervals_10min.append(time_intervals_10min[-1] + duration)\n",
    "\n",
    "time_intervals_10min = [\n",
    "    Time([tstart, tstop]) for tstart, tstop in zip(time_intervals_10min[:-1], time_intervals_10min[1:])\n",
    "]\n",
    "\n",
    "# and now cut the observations in these time intervals\n",
    "short_observations = observations_day.select_time(time_intervals_10min)\n",
    "# check that observations have been filtered\n",
    "print(f\"observations after time filtering: {len(short_observations)}\")\n",
    "print(short_observations[1].gti)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038b3ca0-0b56-4694-bd26-d56b0cf698f2",
   "metadata": {},
   "source": [
    "We have to make data sets out of the new observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef7a46-97f9-40e2-b0e6-747009f1a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_datasets = Datasets()\n",
    "\n",
    "for observation in short_observations:\n",
    "    dataset = dataset_maker.run(\n",
    "        dataset_empty.copy(), observation\n",
    "    )\n",
    "    dataset_on_off = bkg_maker.run(dataset, observation)\n",
    "    short_datasets.append(dataset_on_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee3305-d30f-4079-8ee9-285a83466aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rember to assing the model to the datasets\n",
    "short_datasets.models = [model]\n",
    "\n",
    "light_curve_estimator_10min = LightCurveEstimator(\n",
    "    energy_edges=energy_edges,\n",
    "    time_intervals=time_intervals_10min,\n",
    "    source=\"Mrk421\",\n",
    "    reoptimize=False,\n",
    "    n_sigma_ul=3,\n",
    ")\n",
    "\n",
    "light_curve_10min = light_curve_estimator_10min.run(short_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1858835-9d52-4ee1-8974-fe07b40b65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "light_curve_10min.plot(\n",
    "    ax=ax,\n",
    "    sed_type=\"flux\",\n",
    "    marker=\".\",\n",
    "    label=\"10 min binning\",\n",
    "    alpha=0.6,\n",
    "    time_format=\"mjd\"\n",
    ")\n",
    "light_curve_run_wise.plot(\n",
    "    ax=ax,\n",
    "    sed_type=\"flux\",\n",
    "    marker=\".\",\n",
    "    label=\"run-wise binning\",\n",
    "    alpha=0.6,\n",
    "    time_format=\"mjd\"\n",
    ")\n",
    "light_curve_daily.plot(\n",
    "    ax=ax,\n",
    "    sed_type=\"flux\",\n",
    "    marker=\",\",\n",
    "    label=\"nightly binning\",\n",
    "    elinewidth=2,\n",
    "    time_format=\"mjd\",\n",
    "    alpha=0.2\n",
    "    \n",
    ")\n",
    "ax.set_xlim([56394.8, 56395.2])\n",
    "ax.set_yscale(\"linear\")\n",
    "#ax.set_ylim([0, 4e-10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba2b8b7-c7da-4c21-8965-81b4029b5d24",
   "metadata": {},
   "source": [
    "Let us make a random fit, let us try a linear model, plus a sine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44515e3-e961-4fd2-832b-be64c892a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the datasets by iterating over the returned lightcurve\n",
    "dataset_fp = FluxPointsDataset(data=light_curve_day, name=\"dataset_lc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89997dca-96ec-4430-b950-fc21de2ea096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us use, define the temporal model, midnight of that day is t_ref\n",
    "linear_time_model = LinearTemporalModel(\n",
    "    alpha=2, beta=5 / u.d, t_ref=56395 * u.d\n",
    ")\n",
    "linear_time_model.alpha.frozen = True\n",
    "# let also add a constant spectral model and let us fit\n",
    "spectral_model = ConstantSpectralModel(const=1e-10 * u.Unit(\"TeV-1 cm-2 s-1\"))\n",
    "\n",
    "lc_model = SkyModel(\n",
    "    spectral_model=spectral_model,\n",
    "    temporal_model=linear_time_model,\n",
    "    name=\"time_model\",\n",
    ")\n",
    "\n",
    "dataset_fp.models = lc_model\n",
    "print(dataset_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ef9cc-ff85-4915-bf92-01a0c39f2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = Fit()\n",
    "result = fit.run(dataset_fp)\n",
    "display(result.parameters.to_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed7d7d-fdca-4292-b1c5-ad25cd45b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fp.plot_spectrum(axis_name=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf5c967-c9c4-4fbc-9305-a85f028b44b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
